{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13480225,"sourceType":"datasetVersion","datasetId":8558322}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Aprendizaje one-class\nEste archivo contiene el preprocesamiento y entrenamiento especifico para los modelos one-class.","metadata":{}},{"cell_type":"markdown","source":"****Importanción de librerias y lectura de los datos****","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder,OneHotEncoder\nfrom category_encoders import TargetEncoder\nfrom sklearn.ensemble import IsolationForest \nfrom sklearn.preprocessing import StandardScaler\nfrom tensorflow import keras\nfrom sklearn.metrics import (\n    precision_recall_curve, f1_score, accuracy_score,\n    precision_score, recall_score, average_precision_score,\n    roc_auc_score, confusion_matrix\n)\nfrom sklearn.model_selection import StratifiedKFold\nfrom tensorflow.keras import layers, models, regularizers\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.neighbors import LocalOutlierFactor \nfrom sklearn.feature_selection import mutual_info_classif\nfrom lightgbm import LGBMClassifier\nfrom sklearn.feature_selection import RFECV ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-23T21:22:31.829192Z","iopub.execute_input":"2025-10-23T21:22:31.829514Z","iopub.status.idle":"2025-10-23T21:22:31.838319Z","shell.execute_reply.started":"2025-10-23T21:22:31.829488Z","shell.execute_reply":"2025-10-23T21:22:31.837024Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train = pd.read_csv('/kaggle/input/preprocessedbasedadatos/X_train.csv')\ny_train = pd.read_csv('/kaggle/input/preprocessedbasedadatos/y_train.csv')\nX_val = pd.read_csv('/kaggle/input/preprocessedbasedadatos/X_val.csv')\ny_val = pd.read_csv('/kaggle/input/preprocessedbasedadatos/y_val.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T21:22:31.840445Z","iopub.execute_input":"2025-10-23T21:22:31.842231Z","iopub.status.idle":"2025-10-23T21:23:00.051872Z","shell.execute_reply.started":"2025-10-23T21:22:31.842191Z","shell.execute_reply":"2025-10-23T21:23:00.050828Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Nulos en X_tr_normal_train:\", X_train.isna().sum().sum())\nprint(\"Nulos por columna:\\n\", X_train.isna().sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T21:23:00.053060Z","iopub.execute_input":"2025-10-23T21:23:00.053450Z","iopub.status.idle":"2025-10-23T21:23:02.376997Z","shell.execute_reply.started":"2025-10-23T21:23:00.053417Z","shell.execute_reply":"2025-10-23T21:23:02.375846Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train = X_train.reset_index(drop=True)\ny_train = y_train.reset_index(drop=True)\nX_val   = X_val.reset_index(drop=True)\ny_val   = y_val.reset_index(drop=True)\ny_train = y_train.iloc[:, 0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T21:23:02.378202Z","iopub.execute_input":"2025-10-23T21:23:02.378536Z","iopub.status.idle":"2025-10-23T21:23:03.098186Z","shell.execute_reply.started":"2025-10-23T21:23:02.378502Z","shell.execute_reply":"2025-10-23T21:23:03.096836Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Aplicamos filtrado para el entrenamiento con transacciones normales exclusivamente.    \nmask_normal = (y_train == 0)\nX_tr_normal_train = X_train.loc[mask_normal].copy()\ny_tr_normal_train = y_train.loc[mask_normal].copy()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T21:23:03.100377Z","iopub.execute_input":"2025-10-23T21:23:03.100713Z","iopub.status.idle":"2025-10-23T21:23:04.238967Z","shell.execute_reply.started":"2025-10-23T21:23:03.100688Z","shell.execute_reply":"2025-10-23T21:23:04.237328Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Nulos en X_tr_normal_train:\", X_tr_normal_train.isna().sum().sum())\nprint(\"Nulos por columna:\\n\", X_tr_normal_train.isna().sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T21:23:04.240115Z","iopub.execute_input":"2025-10-23T21:23:04.240446Z","iopub.status.idle":"2025-10-23T21:23:07.695427Z","shell.execute_reply.started":"2025-10-23T21:23:04.240414Z","shell.execute_reply":"2025-10-23T21:23:07.693863Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"****Pruebas con diferentes encodings****","metadata":{}},{"cell_type":"code","source":"###PRUEBA ENCODING CON ONE HOT ENCODING\n#X_tr_normal_train[cat_cols] = X_tr_normal_train[cat_cols].fillna(\"Unknown\")\n#X_val[cat_cols]   = X_val[cat_cols].fillna(\"Unknown\")\n\n#encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n#encoder.fit(X_tr_normal_train[cat_cols])\n\n#X_tr_normal_train_cat = encoder.transform(X_tr_normal_train[cat_cols])\n#X_val_cat   = encoder.transform(X_val[cat_cols])\n#cat_feature_names = encoder.get_feature_names_out(cat_cols)\n#X_tr_normal_train_cat = pd.DataFrame(X_tr_normal_train_cat, columns=cat_feature_names, index=X_tr_normal_train.index)\n#X_val_cat   = pd.DataFrame(X_val_cat, columns=cat_feature_names, index=X_val.index)\n#X_tr_normal_train_final = pd.concat([X_tr_normal_train.drop(columns=cat_cols).reset_index(drop=True), X_tr_normal_train_cat.reset_index(drop=True)], axis=1)\n#X_val_final   = pd.concat([X_val.drop(columns=cat_cols).reset_index(drop=True), X_val_cat.reset_index(drop=True)], axis=1)\n\n#X_tr_normal_train = X_tr_normal_train_final\n#X_val   = X_val_final\n\n#print(\"\\nNuevas dimensiones:\")\n#print(\"Train:\", X_tr_normal_train.shape)\n#print(\"Val:\", X_val.shape)\n\n#print(\"\\nNaNs en train:\", X_tr_normal_train.isna().sum().sum())\n#print(\"NaNs en val:\", X_val.isna().sum().sum())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T21:23:07.696527Z","iopub.execute_input":"2025-10-23T21:23:07.696829Z","iopub.status.idle":"2025-10-23T21:23:07.703604Z","shell.execute_reply.started":"2025-10-23T21:23:07.696807Z","shell.execute_reply":"2025-10-23T21:23:07.702023Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#from category_encoders import HashingEncoder\n\n### PRUEBA ENCODING CON HASHING ENCODER\n# Definir columnas categóricas\n#cat_cols = X_tr_normal_train.select_dtypes(include=['object', 'category']).columns.tolist()\n\n# Definir el encoder (puedes ajustar n_components según dimensionalidad)\n#encoder = HashingEncoder(cols=cat_cols, n_components=8)  # prueba con 8-16, depende de cardinalidad\n\n# Ajustar el encoder y transformar\n#X_tr_normal_train_cat = encoder.fit_transform(X_tr_normal_train[cat_cols])\n#X_val_cat   = encoder.transform(X_val[cat_cols])\n\n# Reconstruir datasets con columnas numéricas originales + categóricas codificadas\n#X_tr_normal_train_final = pd.concat(\n #   [X_tr_normal_train.drop(columns=cat_cols, errors='ignore'), X_tr_normal_train_cat],\n  #  axis=1\n#)\n#X_val_final = pd.concat(\n #   [X_val.drop(columns=cat_cols, errors='ignore'), X_val_cat],\n #   axis=1\n#)\n\n# Sobrescribir variables\n#X_tr_normal_train = X_tr_normal_train_final\n#X_val = X_val_final\n\n#print(\"\\nNuevas dimensiones:\")\n#print(\"Train:\", X_tr_normal_train.shape)\n#print(\"Val:\", X_val.shape)\n\n#print(\"\\nNaNs en train:\", X_tr_normal_train.isna().sum().sum())\n#print(\"NaNs en val:\", X_val.isna().sum().sum())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T21:23:07.704851Z","iopub.execute_input":"2025-10-23T21:23:07.705336Z","iopub.status.idle":"2025-10-23T21:23:07.736787Z","shell.execute_reply.started":"2025-10-23T21:23:07.705282Z","shell.execute_reply":"2025-10-23T21:23:07.735547Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"###PRUEBA ENCODING CON TARGET ENCODING\n#encoder = TargetEncoder(cols=cat_cols, handle_missing='value', handle_unknown='value')\n#encoder.fit(X_tr_normal_train[cat_cols], y_normal_train)\n#X_tr_normal_train_cat = encoder.transform(X_tr_normal_train[cat_cols])\n#X_val_cat   = encoder.transform(X_val[cat_cols])\n#X_tr_normal_train_final = pd.concat([X_tr_normal_train.drop(columns=cat_cols, errors='ignore'), X_tr_normal_train_cat], axis=1)\n#X_val_final   = pd.concat([X_val.drop(columns=cat_cols, errors='ignore'), X_val_cat], axis=1)\n#X_tr_normal_train = X_tr_normal_train_final\n#X_val = X_val_final\n\n#print(\"\\nNuevas dimensiones:\")\n#print(\"Train:\", X_tr_normal_train.shape)\n#print(\"Val:\", X_val.shape)\n\n#print(\"\\nNaNs en train:\", X_tr_normal_train.isna().sum().sum())\n#print(\"NaNs en val:\", X_val.isna().sum().sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T21:23:07.738368Z","iopub.execute_input":"2025-10-23T21:23:07.738827Z","iopub.status.idle":"2025-10-23T21:23:07.766023Z","shell.execute_reply.started":"2025-10-23T21:23:07.738783Z","shell.execute_reply":"2025-10-23T21:23:07.764857Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"###PRUEBA CON FRECUENCY ENCODING \n#cat_cols = X_tr_normal_train.select_dtypes(include=['object', 'category']).columns.tolist()\n\n#for col in cat_cols:\n #   freq = X_tr_normal_train[col].value_counts(normalize=True)\n #   X_tr_normal_train[col] = X_tr_normal_train[col].map(freq)\n #   X_val[col] = X_val[col].map(freq)\n #   X_tr_normal_train[col] = X_tr_normal_train[col].fillna(0)\n #   X_val[col] = X_val[col].fillna(0)\n\n#print(\"\\nNuevas dimensiones:\")\n#print(\"Train:\", X_tr_normal_train.shape)\n#print(\"Val:\", X_val.shape)\n#print(\"\\nNaNs en train:\", X_tr_normal_train.isna().sum().sum())\n#print(\"NaNs en val:\", X_val.isna().sum().sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T21:23:07.766835Z","iopub.execute_input":"2025-10-23T21:23:07.767180Z","iopub.status.idle":"2025-10-23T21:23:07.794007Z","shell.execute_reply.started":"2025-10-23T21:23:07.767158Z","shell.execute_reply":"2025-10-23T21:23:07.792152Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Identificar columnas categóricas\ncat_cols = X_tr_normal_train.select_dtypes(include=['object', 'category']).columns.tolist()\nprint(cat_cols)\n\n\nfor col in cat_cols:\n    le = LabelEncoder()\n    X_tr_normal_train.loc[:, col] = le.fit_transform(X_tr_normal_train[col].astype(str))\n    \n    if col in X_val.columns:\n        vals = X_val[col].astype(str)\n        vals = vals.map(lambda x: x if x in le.classes_ else None)\n        vals = vals.fillna(\"UNK\")\n        if \"UNK\" not in le.classes_:\n            le.classes_ = np.append(le.classes_, \"UNK\")\n        X_val.loc[:, col] = le.transform(vals)\n\nprint(\"\\nNuevas dimensiones:\")\nprint(\"Train:\", X_tr_normal_train.shape)\nprint(\"Val:\", X_val.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T21:23:07.796126Z","iopub.execute_input":"2025-10-23T21:23:07.796517Z","iopub.status.idle":"2025-10-23T21:23:36.312203Z","shell.execute_reply.started":"2025-10-23T21:23:07.796481Z","shell.execute_reply":"2025-10-23T21:23:36.310932Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Nulos en X_tr_normal_train:\", X_tr_normal_train.isna().sum().sum())\nprint(\"Nulos por columna:\\n\", X_tr_normal_train.isna().sum())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T21:23:36.312895Z","iopub.execute_input":"2025-10-23T21:23:36.313193Z","iopub.status.idle":"2025-10-23T21:23:38.502327Z","shell.execute_reply.started":"2025-10-23T21:23:36.313173Z","shell.execute_reply":"2025-10-23T21:23:38.501065Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"****Pruebas de selección de columnas con el top 100**** ","metadata":{}},{"cell_type":"code","source":"#discrete_mask = X_tr_normal_train.columns.isin(cat_cols)\n#importancias = mutual_info_classif(X_tr_normal_train,y_normal_train,discrete_features=discrete_mask, random_state=42)\n#importancias = pd.Series(importancias, index = X_tr_normal_train.columns).sort_values(ascending=False)\n#top = 200\n#top_columnas = importancias.head(top).index.tolist()\n\n#X_tr_normal_train = X_tr_normal_train[top_columnas]\n#X_val = X_val[top_columnas]\n\n#plt.figure(figsize=(10,6))\n#importancias.head(70).plot(kind='bar')\n#plt.title('Top 100 columnas según relevancia')\n#plt.tight_layout()\n#plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T21:23:38.503421Z","iopub.execute_input":"2025-10-23T21:23:38.503762Z","iopub.status.idle":"2025-10-23T21:23:38.509306Z","shell.execute_reply.started":"2025-10-23T21:23:38.503734Z","shell.execute_reply":"2025-10-23T21:23:38.508012Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n#modelo_importancias = LGBMClassifier(n_estimators=100,random_state=42,n_jobs=-1)\n#rfecv= RFECV (estimator=modelo_importancias, step=1,cv=StratifiedKFold(3),scoring= 'average_precision', min_features_to_select=100)\n#rfecv.fit(X_tr_normal_train,y_normal_train)\n#print(\"Número óptimo de variables:\", rfecv.n_features_)\n#selected_features= X_tr_normal_train.columns[rfecv.support_]\n\n#X_tr_normal_train= X_tr_normal_train[selected_features]\n#X_val = X_val[selected_features]\n\n#plt.figure(figsize=(8,4))\n#plt.plot(\n #   range(1, len(rfecv.cv_results_['mean_test_score']) + 1),\n #   rfecv.cv_results_['mean_test_score']\n#)\n#plt.xlabel(\"Número de variables\")\n#plt.ylabel(\"PR AUC\")\n#plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T21:23:38.513039Z","iopub.execute_input":"2025-10-23T21:23:38.513311Z","iopub.status.idle":"2025-10-23T21:23:38.538176Z","shell.execute_reply.started":"2025-10-23T21:23:38.513287Z","shell.execute_reply":"2025-10-23T21:23:38.536843Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"****Escalado de la base de datos y entrenamiento del modelo LOF****","metadata":{}},{"cell_type":"code","source":"\n#Realizamos el escalado, mejora el rendimiento general de los modelos.\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_tr_normal_train)  # solo normales\nX_val_scaled = scaler.transform(X_val)\n\nprint(\"Nulos en X_tr_normal_train:\", X_tr_normal_train.isna().sum().sum())\nprint(\"Nulos por columna:\\n\", X_tr_normal_train.isna().sum())\n\n#X_tr_normal_train = X_tr_normal_train.reset_index(drop=True)\n#y_normal_train = y_normal_train.reset_index(drop=True)\n\nlof = LocalOutlierFactor(n_neighbors=15, contamination=0.035,novelty=True,leaf_size=50, n_jobs =-1)\nlof.fit(X_train_scaled)\n\n# Scores en validación\nval_scores = -lof.decision_function(X_val_scaled)\n\n# Buscar mejor threshold\nprecision, recall, thresholds = precision_recall_curve(y_val, val_scores)\nf1_scores = 2 * (precision * recall) / (precision + recall + 1e-6)\nbest_idx = np.argmax(f1_scores)\nbest_thr = thresholds[best_idx]\n\ny_pred = (val_scores >= best_thr).astype(int)\n\nprint(f\"Mejor F1={f1_scores[best_idx]:.4f}, con threshold={best_thr:.4f}\")\nprint(\"Accuracy:\", accuracy_score(y_val, y_pred))\nprint(\"Precision:\", precision_score(y_val, y_pred, zero_division=0))\nprint(\"Recall:\", recall_score(y_val, y_pred, zero_division=0))\nprint(\"F1:\", f1_score(y_val, y_pred, zero_division=0))\nprint(\"PR AUC:\", average_precision_score(y_val, val_scores))\nprint(\"ROC AUC:\", roc_auc_score(y_val, val_scores))\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_pred))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-23T21:23:38.539266Z","iopub.execute_input":"2025-10-23T21:23:38.539536Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"****Entrenamiento del modelo Autoencoder****","metadata":{}},{"cell_type":"code","source":"#Definimos las capas del autoencoder\n\ninp = layers.Input(shape=(X_train_scaled.shape[1],))\nencoded = layers.Dense(32, activation=\"relu\",\n                       activity_regularizer=regularizers.l1(1e-5))(inp)\nz = layers.Dense(8, activation=\"relu\")(encoded)\ndecoded = layers.Dense(32, activation=\"relu\")(z)\nout = layers.Dense(X_train_scaled.shape[1], activation=\"linear\")(decoded)\n\nautoencoder = models.Model(inp, out)\nencoder = models.Model(inp, z)\nautoencoder.compile(optimizer=\"adam\", loss=\"mae\")\n\nearly_stop = EarlyStopping(\n    monitor=\"val_loss\", patience=5, restore_best_weights=True\n)\n\nautoencoder.fit(\n    X_train_scaled, X_train_scaled,\n    validation_data=(X_val_scaled, X_val_scaled),\n    epochs=50, batch_size=16,\n    callbacks=[early_stop], verbose=1,\n)\n\nrecon_val = autoencoder.predict(X_val_scaled)\nval_scores = np.mean((X_val_scaled - recon_val) ** 2, axis=1)\n\n# Buscar mejor threshold por F1\nprecision, recall, thresholds = precision_recall_curve(y_val, val_scores)\nf1_scores = 2 * (precision * recall) / (precision + recall + 1e-6)\nbest_idx = np.argmax(f1_scores)\nbest_thr = thresholds[best_idx]\n\ny_pred = (val_scores >= best_thr).astype(int)\n\nprint(\"\\n### Autoencoder ###\")\nprint(f\"Mejor F1={f1_scores[best_idx]:.4f}, con threshold={best_thr:.4f}\")\nprint(\"Accuracy:\", accuracy_score(y_val, y_pred))\nprint(\"Precision:\", precision_score(y_val, y_pred, zero_division=0))\nprint(\"Recall:\", recall_score(y_val, y_pred, zero_division=0))\nprint(\"F1:\", f1_score(y_val, y_pred, zero_division=0))\nprint(\"PR AUC:\", average_precision_score(y_val, val_scores))\nprint(\"ROC AUC:\", roc_auc_score(y_val, val_scores))\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_pred))\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"****Entrenamiento del modelo Isolation Forest****","metadata":{}},{"cell_type":"code","source":"iso = IsolationForest(n_estimators = 150, max_samples = 512, contamination=0.035,bootstrap= True, random_state=42, n_jobs=-1)\niso.fit(X_train_scaled)\nval_scores = -iso.decision_function(X_val_scaled)  # mayor = más anómalo\n\n# Buscar mejor threshold\nprecision, recall, thresholds = precision_recall_curve(y_val, val_scores)\nf1_scores = 2 * (precision * recall) / (precision + recall + 1e-6)\nbest_idx = np.argmax(f1_scores)\nbest_thr = thresholds[best_idx]\n\ny_pred = (val_scores >= best_thr).astype(int)\n\nprint(f\"Mejor F1={f1_scores[best_idx]:.4f}, con threshold={best_thr:.4f}\")\nprint(\"Accuracy:\", accuracy_score(y_val, y_pred))\nprint(\"Precision:\", precision_score(y_val, y_pred, zero_division=0))\nprint(\"Recall:\", recall_score(y_val, y_pred, zero_division=0))\nprint(\"F1:\", f1_score(y_val, y_pred, zero_division=0))\nprint(\"PR AUC:\", average_precision_score(y_val, val_scores))\nprint(\"ROC AUC:\", roc_auc_score(y_val, val_scores))\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_pred))","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}