{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizaje Supervisado\n",
    "Este archivo contiene el preprocesamiento y entrenamiento realizado para los modelos de aprendizaje supervisado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importación de las librerías y carga de datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "14b3f40f-85d5-4ba0-9533-75f65c1e0615",
    "_uuid": "16b25ec029df1bc05f5b3882f9bd92f14a84f970",
    "execution": {
     "iopub.execute_input": "2025-10-23T17:52:08.596120Z",
     "iopub.status.busy": "2025-10-23T17:52:08.595623Z",
     "iopub.status.idle": "2025-10-23T17:52:08.605109Z",
     "shell.execute_reply": "2025-10-23T17:52:08.603615Z",
     "shell.execute_reply.started": "2025-10-23T17:52:08.596079Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import imblearn.over_sampling  as ovs\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    average_precision_score,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    ")\n",
    "import shap\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T17:52:08.607477Z",
     "iopub.status.busy": "2025-10-23T17:52:08.607094Z",
     "iopub.status.idle": "2025-10-23T17:52:35.539541Z",
     "shell.execute_reply": "2025-10-23T17:52:35.537793Z",
     "shell.execute_reply.started": "2025-10-23T17:52:08.607451Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('/kaggle/input/preprocessedbasedadatos/X_train.csv')\n",
    "y_train = pd.read_csv('/kaggle/input/preprocessedbasedadatos/y_train.csv')\n",
    "X_val = pd.read_csv('/kaggle/input/preprocessedbasedadatos/X_val.csv')\n",
    "y_val = pd.read_csv('/kaggle/input/preprocessedbasedadatos/y_val.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Aplicación de Label Encoding****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T17:52:35.542019Z",
     "iopub.status.busy": "2025-10-23T17:52:35.541504Z",
     "iopub.status.idle": "2025-10-23T17:52:39.249244Z",
     "shell.execute_reply": "2025-10-23T17:52:39.247012Z",
     "shell.execute_reply.started": "2025-10-23T17:52:35.541982Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cat_cols = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    \n",
    "    le.fit(X_train[col].astype(str))\n",
    "    X_train[col] = le.transform(X_train[col].astype(str))    \n",
    "\n",
    "    if col in X_val.columns:\n",
    "        val_vals = X_val[col].astype(str)\n",
    "        # Identificar clases desconocidas\n",
    "        mask_desconocidas = ~val_vals.isin(le.classes_)\n",
    "        \n",
    "        if mask_desconocidas.any():\n",
    "            # Agregar 'UNK' si no existe\n",
    "            if 'UNK' not in le.classes_:\n",
    "                le.classes_ = np.append(le.classes_, 'UNK')\n",
    "            # Reemplazar valores desconocidos por 'UNK'\n",
    "            val_vals.loc[mask_desconocidas] = 'UNK'\n",
    "\n",
    "        # Finalmente transformar\n",
    "        X_val[col] = le.transform(val_vals)\n",
    "print(\"\\nNuevas dimensiones:\")\n",
    "print(\"Train:\", X_train.shape)\n",
    "print(\"Val:\", X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Aplicación de Hashing Encoding****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T17:52:39.252757Z",
     "iopub.status.busy": "2025-10-23T17:52:39.252316Z",
     "iopub.status.idle": "2025-10-23T17:52:39.260059Z",
     "shell.execute_reply": "2025-10-23T17:52:39.258373Z",
     "shell.execute_reply.started": "2025-10-23T17:52:39.252723Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#from category_encoders import HashingEncoder\n",
    "\n",
    "#encoder = HashingEncoder(cols=cat_cols, n_components=8)  # prueba con 8-16, depende de cardinalidad\n",
    "\n",
    "#X_train_cat = encoder.fit_transform(X_train[cat_cols])\n",
    "#X_val_cat   = encoder.transform(X_val[cat_cols])\n",
    "\n",
    "# Reconstruir datasets con columnas numéricas originales + categóricas codificadas\n",
    "#X_train_final = pd.concat(\n",
    "  #  [X_train.drop(columns=cat_cols, errors='ignore'), X_train_cat],\n",
    " #   axis=1\n",
    "#)\n",
    "#X_val_final = pd.concat(\n",
    "#    [X_val.drop(columns=cat_cols, errors='ignore'), X_val_cat],\n",
    "#    axis=1\n",
    "#)\n",
    "\n",
    "# Sobrescribir variables\n",
    "#X_train = X_train_final\n",
    "#X_val = X_val_final\n",
    "\n",
    "#print(\"\\nNuevas dimensiones:\")\n",
    "#print(\"Train:\", X_train.shape)\n",
    "#print(\"Val:\", X_val.shape)\n",
    "\n",
    "#print(\"\\nNaNs en train:\", X_train.isna().sum().sum())\n",
    "#print(\"NaNs en val:\", X_val.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Selección de columnas****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-23T17:52:39.262016Z",
     "iopub.status.busy": "2025-10-23T17:52:39.261660Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "importancias = mutual_info_classif(X_train,y_train,random_state=42)\n",
    "importancias = pd.Series(importancias, index = X_train.columns).sort_values(ascending=False)\n",
    "top = 250\n",
    "top_columnas = importancias.head(top).index.tolist()\n",
    "\n",
    "X_train = X_train[top_columnas]\n",
    "X_val = X_val[top_columnas]\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "importancias.head(250).plot(kind='bar')\n",
    "plt.title('Top 250 columnas según relevancia')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Modelo base\n",
    "#modelo = LGBMClassifier(\n",
    "    #n_estimators=500,\n",
    "   # max_depth=-1,\n",
    "   # learning_rate=0.05,\n",
    "   # num_leaves=31,\n",
    "  #  subsample=0.8,\n",
    "  #  colsample_bytree=0.8,\n",
    " #   random_state=42,\n",
    " #   n_jobs=-1\n",
    "#)\n",
    "\n",
    "#step_size = 5\n",
    "#n_features_initial = X_train.shape[1]  # número total de variables\n",
    "\n",
    "#rfecv = RFECV(\n",
    " #   estimator=modelo,\n",
    " #  step=step_size,\n",
    " #   cv=StratifiedKFold(3),\n",
    " #   scoring='average_precision',\n",
    " #   min_features_to_select=50,\n",
    " #   n_jobs=-1,\n",
    " #   verbose=1\n",
    "#)\n",
    "\n",
    "#rfecv.fit(X_train, y_train)\n",
    "#print(\"Número óptimo de variables:\", rfecv.n_features_)\n",
    "\n",
    "#num_iters = len(rfecv.cv_results_['mean_test_score'])\n",
    "#num_features_per_iter = [\n",
    " #   n_features_initial - (i * step_size) for i in range(num_iters)\n",
    "#]\n",
    "\n",
    "#plt.figure(figsize=(10, 5))\n",
    "#plt.plot(\n",
    "   # num_features_per_iter,\n",
    "  #  rfecv.cv_results_['mean_test_score'],\n",
    " #   marker='o'\n",
    "#)\n",
    "#plt.xlabel(\"Número de variables\")\n",
    "#plt.ylabel(\"PR AUC\")\n",
    "#plt.title(\"RFECV - LightGBM (step = 5)\")\n",
    "#plt.grid(alpha=0.3)\n",
    "#plt.show()\n",
    "\n",
    "#X_train.to_csv(\"train_reduced_rfecv.csv\", index=False)\n",
    "#X_val.to_csv(\"val_reduced_rfecv.csv\", index=False)\n",
    "#y_train.to_csv(\"y_train_reduced_rfecv.csv\",index=False)\n",
    "#y_val.to_csv(\"y_val_reduced_rfecv.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Aplicación de la técnica de SMOTE****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#smote = SMOTE(sampling_strategy= 0.4 , random_state=42)\n",
    "#batch_size = 50000\n",
    "\n",
    "# Barajar X_train e y_train mateniendo los indices\n",
    "#idx = np.random.permutation(len(X_train))\n",
    "#X_train = X_train.iloc[idx].reset_index(drop=True)\n",
    "#y_train = y_train.iloc[idx].reset_index(drop=True)\n",
    "\n",
    "#X_res_all, y_res_all = [], []\n",
    "\n",
    "# Aplicar SMOTE por lotes\n",
    "#for i in range(0, len(X_train), batch_size):\n",
    " #   X_b = X_train.iloc[i:i+batch_size]\n",
    " #   y_b = y_train.iloc[i:i+batch_size]\n",
    "\n",
    "  #  if y_b.sum() > 0: \n",
    "   #     X_r, y_r = smote.fit_resample(X_b, y_b)\n",
    "   # else:\n",
    "    #    X_r, y_r = X_b, y_b  \n",
    "\n",
    "   # X_res_all.append(X_r)\n",
    "   # y_res_all.append(y_r)\n",
    "\n",
    "#X_train_smote = pd.concat(X_res_all, ignore_index=True)\n",
    "#y_train_smote = pd.concat(y_res_all, ignore_index=True)\n",
    "\n",
    "#print(\"Shape final:\", X_train_smote.shape)\n",
    "#print(\"Distribución de clases después de SMOTE:\\n\", y_train_smote.value_counts(normalize=True))\n",
    "\n",
    "#X_train = X_train_smote\n",
    "#y_train = y_train_smote\n",
    "\n",
    "# Exportar conjuntos\n",
    "#X_train.to_csv(\"train_smote.csv\", index=False)\n",
    "#y_train.to_csv(\"y_train_smote.csv\", index=False)\n",
    "\n",
    "#X_val.to_csv(\"val_smote.csv\", index=False)\n",
    "#y_val.to_csv(\"y_val_smote.csv\", index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Lista de modelos supervisados\n",
    "modelos = {\n",
    "\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        n_estimators=500,\n",
    "        max_depth=4,\n",
    "        learning_rate=0.4,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "    ),\n",
    "    \"RandomForest\": RandomForestClassifier(\n",
    "        n_estimators=500,      \n",
    "       max_depth=None,\n",
    "       class_weight='balanced_subsample'\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    \n",
    "    \"LightGBM\" : LGBMClassifier (\n",
    "        n_estimators = 500, \n",
    "        max_depth = -1,\n",
    "        learning_rate = 0.05,\n",
    "        num_leaves = 31,\n",
    "        subsample = 0.8,\n",
    "        colsample_bytree = 0.8,\n",
    "        random_state= 42,\n",
    "        is_unbalance=True,\n",
    "        n_jobs = -1\n",
    "    )\n",
    "}\n",
    "\n",
    "resultados = []\n",
    "threshold =  0.15\n",
    "for nombre, modelo in modelos.items():\n",
    "    print(f\"\\nEntrenando {nombre}...\")\n",
    "    modelo.fit(X_train, y_train)\n",
    "\n",
    "    # Predicciones y probabilidades\n",
    "    y_pred = modelo.predict(X_val)\n",
    "    if hasattr(modelo, \"predict_proba\"):\n",
    "        y_scores = modelo.predict_proba(X_val)[:, 1]\n",
    "    else:\n",
    "        y_scores = modelo.decision_function(X_val)\n",
    "\n",
    "    # Métricas\n",
    "    y_pred = (y_scores>=threshold).astype(int)\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_val, y_pred, zero_division=0)\n",
    "    pr_auc = average_precision_score(y_val, y_scores)\n",
    "    roc_auc = roc_auc_score(y_val,y_scores)\n",
    "    cm = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "    resultados.append({\n",
    "        \"Modelo\": nombre,\n",
    "        \"Accuracy\": acc,\n",
    "        \"Precision\": prec,\n",
    "        \"Recall\": rec,\n",
    "        \"F1\": f1,\n",
    "        \"PR AUC\": pr_auc,\n",
    "        \"ROC AUC\": roc_auc,\n",
    "        \"Matriz_Confusion\": cm\n",
    "    })\n",
    "\n",
    "# Mostrar tabla comparativa\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "print(\"\\nResultados comparativos:\")\n",
    "print(df_resultados[[\"Modelo\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\", \"PR AUC\",\"ROC AUC\"]])\n",
    "\n",
    "# Mostrar matrices de confusión\n",
    "for r in resultados:\n",
    "    print(f\"\\nMatriz de confusión para {r['Modelo']}:\")\n",
    "    print(r[\"Matriz_Confusion\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Top importancias para Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Obtener importancias\n",
    "importancias = modelo.feature_importances_\n",
    "nombres_caracteristicas = X_train.columns\n",
    "\n",
    "df_importancias = pd.DataFrame({\n",
    "    \"Característica\": nombres_caracteristicas,\n",
    "    \"Importancia\": importancias\n",
    "}).sort_values(by=\"Importancia\", ascending=False)\n",
    "\n",
    "# Top 10\n",
    "df_top10 = df_importancias.head(10)\n",
    "\n",
    "print(\"\\nTop 10 características más importantes:\")\n",
    "print(df_top10)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.barh(df_top10[\"Característica\"], df_top10[\"Importancia\"], color=\"#1f77b4\")\n",
    "plt.gca().invert_yaxis()  # Mostrar la más importante arriba\n",
    "plt.title(\"Top 10 - Importancia de características (Random Forest)\", fontsize=16)\n",
    "plt.xlabel(\"Importancia\", fontsize=12)\n",
    "plt.ylabel(\"Característica\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generación del csv de entrega a la competición"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = modelo.predict_proba(X_val)[:,1]\n",
    "entrega = pd.DataFrame({\n",
    "    'TransactionID' : X_val['TransactionID'],\n",
    "    'isFraud': y_pred\n",
    "})\n",
    "\n",
    "entrega.to_csv('submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7296249,
     "sourceId": 11629338,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8558322,
     "sourceId": 13480225,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
